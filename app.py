import os
import google.generativeai as genai
from elevenlabs.client import ElevenLabs
# Removed 'save' as it wasn't used directly after the change
# from elevenlabs import save
from flask import Flask, render_template, request, jsonify, send_file
from dotenv import load_dotenv
import io # Required for sending audio data and BytesIO
import json # Added for potential JSON parsing/validation
import traceback # For detailed error logging

# --- Configuration ---
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
ELEVENLABS_VOICE_ID = os.getenv("ELEVENLABS_VOICE_ID")

if not GEMINI_API_KEY:
    raise ValueError("Gemini API key not found. Make sure it's set in the .env file.")
if not ELEVENLABS_API_KEY:
    print("Warning: ElevenLabs API key not found. TTS features will be disabled.")
if not ELEVENLABS_VOICE_ID and ELEVENLABS_API_KEY:
    print("Warning: ElevenLabs Voice ID not found. Default voice may be used or TTS might fail.")

# Configure Gemini
try:
    genai.configure(api_key=GEMINI_API_KEY)
    gemini_model = genai.GenerativeModel('gemini-1.5-flash') # Or other suitable model
    print("Gemini client configured.")
except Exception as e:
     print(f"Error configuring Gemini: {e}")
     # Decide if you want the app to stop or continue without Gemini
     raise ValueError(f"Failed to configure Gemini: {e}")


# Configure ElevenLabs (only if key is present)
elevenlabs_client = None # Initialize to None
if ELEVENLABS_API_KEY and ELEVENLABS_VOICE_ID:
    try:
        elevenlabs_client = ElevenLabs(api_key=ELEVENLABS_API_KEY)
        # Optional: You could add a small API call here to test the key/voice validity if needed
        # Example check (costs API call): voices = elevenlabs_client.voices.get_all()
        print("ElevenLabs client configured.")
    except Exception as e:
        print(f"Error configuring ElevenLabs client: {e}")
        traceback.print_exc() # Print full traceback for config error
        elevenlabs_client = None # Ensure it's None on error

# --- Flask App ---
app = Flask(__name__)

# --- Helper Functions ---
def generate_gemini_content(prompt, safety_settings=None):
    """Generates content using the Gemini API."""
    if not GEMINI_API_KEY:
        return "Error: Gemini API key not configured."
    if not gemini_model: # Check if model initialized correctly
         return "Error: Gemini model not initialized."
    try:
        # Using gemini-1.5-flash which is generally good and fast
        response = gemini_model.generate_content(
            prompt,
            # generation_config=genai.types.GenerationConfig(...) # Optional config
            # safety_settings=safety_settings # Optional safety settings
        )
        # Handle potential lack of text in response or blocked content
        if not response.parts:
             if response.prompt_feedback.block_reason:
                 return f"Error: Content blocked by safety filters. Reason: {response.prompt_feedback.block_reason.name}"
             else:
                 # Try to get candidate information if available
                 candidate_info = getattr(response, 'candidates', [None])[0]
                 finish_reason = getattr(candidate_info, 'finish_reason', 'UNKNOWN')
                 if finish_reason != 'STOP':
                      return f"Error: Generation stopped unexpectedly. Reason: {finish_reason}"
                 return "Error: No content generated by the API. The prompt might be problematic or the API unavailable."

        return response.text
    except Exception as e:
        print(f"Gemini API Error: {e}")
        traceback.print_exc() # Print full traceback
        # Provide more specific error messages if possible
        error_str = str(e).lower()
        if "api key not valid" in error_str:
             return "Error: Invalid Gemini API Key."
        if "quota" in error_str:
             return "Error: API quota exceeded. Please check your Gemini plan."
        return f"Error: Could not connect to or generate from Gemini API. Details: {e}"

# --- *** CORRECTED generate_elevenlabs_speech Function START *** ---
def generate_elevenlabs_speech(text):
    """Generates speech using the ElevenLabs API, consumes the stream, and returns audio bytes."""
    if not elevenlabs_client:
        print("Skipping TTS generation as ElevenLabs client is not configured.")
        return None # Return None if client not configured

    try:
        print(f"Generating speech for: '{text[:50]}...'") # Log generation attempt

        # Generate audio - this returns an iterator (generator) yielding audio chunks
        audio_stream = elevenlabs_client.generate(
            text=text,
            voice=ELEVENLABS_VOICE_ID,
            model="eleven_multilingual_v2", # Or another suitable model
            stream=True # Explicitly use streaming
        )

        # --- Consume the generator stream ---
        audio_bytes_list = []
        for chunk in audio_stream:
            if chunk: # Make sure chunk is not None or empty
                audio_bytes_list.append(chunk)

        # Join the collected chunks into a single bytes object
        full_audio_bytes = b"".join(audio_bytes_list)
        # --- End consuming stream ---

        if not full_audio_bytes:
             print("ElevenLabs Error: No audio data generated or received from stream.")
             return None

        # Now we have the full bytes, we can get the length
        print(f"Generated {len(full_audio_bytes)} bytes of audio.")
        return full_audio_bytes # Return the complete bytes object

    except Exception as e:
        print(f"ElevenLabs API Error: {e}") # Log the primary error message
        error_str = str(e).lower()
        # Add specific checks if possible
        if "401" in error_str or "unauthorized" in error_str:
            print("ElevenLabs Error: Authentication failed (Check API Key?).")
        elif "voice" in error_str and "not found" in error_str:
             print(f"ElevenLabs Error: Voice ID '{ELEVENLABS_VOICE_ID}' not found.")
        elif "quota" in error_str or "limit" in error_str:
             print("ElevenLabs Error: Quota or rate limit likely exceeded.")
        # Log the full traceback for unexpected errors
        traceback.print_exc()
        return None # Return None on any error during generation/streaming
# --- *** CORRECTED generate_elevenlabs_speech Function END *** ---


# --- Flask Routes ---

@app.route('/')
def index():
    """Renders the main HTML page."""
    # Define grammar topics here (can be expanded)
    grammar_topics = {
        "Encounter": ["Basic Sentence Structure (SVO)", "Present Simple Tense", "Articles (a, an, the)", "Nouns (Singular/Plural)"],
        "Investigation": ["Past Simple Tense", "Present Continuous Tense", "Adjectives and Adverbs", "Prepositions of Place"],
        "Awakening": ["Future Simple Tense", "Modal Verbs (can, could, will, would)", "Comparatives/Superlatives", "Present Perfect Tense"],
        "Summit": ["Past Perfect Tense", "Passive Voice", "Reported Speech", "Conditional Sentences (Type 1 & 2)"],
        "Expert": ["Conditional Sentences (Type 3 & Mixed)", "Relative Clauses", "Advanced Punctuation", "Phrasal Verbs nuances"]
    }
    paraphrase_styles = ["Formal", "Informal", "Simpler", "More Detailed", "Creative", "Neutral"]
    levels = ["Encounter", "Investigation", "Awakening", "Summit", "Expert"]

    # Pass the boolean status of the elevenlabs client
    elevenlabs_ready_status = bool(elevenlabs_client)
    print(f"Rendering index.html with elevenlabs_ready={elevenlabs_ready_status}") # Log status

    return render_template('index.html',
                           grammar_topics=grammar_topics,
                           paraphrase_styles=paraphrase_styles,
                           levels=levels,
                           elevenlabs_ready=elevenlabs_ready_status # Pass the status here
                          )

# Helper to safely parse JSON from Gemini, trying to strip markdown/text
def parse_gemini_json(raw_response, tool_name="Unknown"):
     try:
        # Find the start and end of the JSON object
        json_start = raw_response.find('{')
        json_end = raw_response.rfind('}') + 1

        if json_start != -1 and json_end != 0:
             json_str = raw_response[json_start:json_end]
             parsed_json = json.loads(json_str)
             return parsed_json
        else:
            # Handle cases where Gemini returns an error string or non-JSON format
            print(f"{tool_name} - Gemini did not return valid JSON structure. Raw response: {raw_response}")
            raise ValueError("API did not return a recognizable JSON object.")

     except (json.JSONDecodeError, ValueError) as e:
        print(f"{tool_name} - Error parsing Gemini JSON response: {e}. Raw response: {raw_response}")
        # Re-raise the exception to be handled by the calling route
        raise e
     except Exception as e: # Catch other potential errors during processing
        print(f"{tool_name} - Unexpected error during JSON parsing: {e}")
        raise e

@app.route('/correct', methods=['POST'])
def correct_text():
    """Corrects the submitted text."""
    data = request.get_json()
    if not data or 'text' not in data:
         return jsonify({"error": "Invalid request data."}), 400
    text_to_correct = data.get('text')
    if not text_to_correct:
        return jsonify({"error": "No text provided."}), 400

    prompt = f"""
    Analyze the following English text for grammatical errors, spelling mistakes, punctuation issues, and awkward phrasing.
    Provide a corrected version of the text.
    Then, provide a detailed, bulleted list explaining each correction made. For each point, clearly state the original mistake, the correction, and the relevant grammar rule or reason for the change. Use examples if helpful.

    Original Text:
    "{text_to_correct}"

    Respond ONLY in the following JSON format. Do not include any text before or after the JSON object:
    {{
      "corrected_text": "The corrected version here...",
      "feedback": [
        {{ "mistake": "Original snippet", "correction": "Corrected snippet", "explanation": "Detailed explanation..." }}
      ]
    }}
    """
    raw_result = generate_gemini_content(prompt)
    if raw_result.startswith("Error:"):
        return jsonify({"error": "Failed to get correction from AI.", "details": raw_result}), 500

    try:
        parsed_json = parse_gemini_json(raw_result, "Corrector")
        # Basic validation of expected keys
        if "corrected_text" not in parsed_json or "feedback" not in parsed_json:
            raise ValueError("Missing required keys in Gemini response")
        return jsonify(parsed_json)
    except Exception as e:
        # Fallback if parsing failed
        return jsonify({
            "error": f"Could not parse the correction response: {e}",
            "details": f"Raw API response: {raw_result}"
        }), 500


@app.route('/generate_topic', methods=['POST'])
def generate_topic_explanation():
    """Generates explanation and questions for a specific grammar topic and level."""
    data = request.get_json()
    if not data:
         return jsonify({"error": "Invalid request data."}), 400
    topic = data.get('topic')
    level = data.get('level')
    if not topic or not level:
        return jsonify({"error": "Topic and level are required."}), 400

    prompt = f"""
    Generate a clear and detailed explanation of the English grammar topic "{topic}" suitable for the "{level}" level (Encounter=beginner, Expert=advanced).
    Use simple language for lower levels and more technical terms for higher levels. Include examples.
    After the explanation, create 5 distinct interactive questions (e.g., multiple-choice, fill-in-the-blank) to test understanding.
    Format the output ONLY as a JSON object. Do not include any text before or after the JSON object:
    {{
      "explanation_html": "...",
      "questions": [
        {{ "id": "topic_q1", "type": "...", "question_html": "...", "answer": "..." }},
        {{ "id": "topic_q2", "type": "...", "question_html": "...", "answer": "..." }},
        {{ "id": "topic_q3", "type": "...", "question_html": "...", "answer": "..." }},
	{{ "id": "topic_q4", "type": "...", "question_html": "...", "answer": "..." }},
	{{ "id": "topic_q5", "type": "...", "question_html": "...", "answer": "..." }}
      ]
    }}
    Use unique IDs like 'topic_q1', 'topic_q2'. For question_html, include necessary HTML inputs (radio buttons with name=id, text inputs with data-question-id=id).
    """
    raw_result = generate_gemini_content(prompt)
    if raw_result.startswith("Error:"):
        return jsonify({"error": "Failed to generate topic explanation from AI.", "details": raw_result}), 500

    try:
        json_result = parse_gemini_json(raw_result, "Topic Generator")
        # Basic validation
        if 'explanation_html' in json_result and 'questions' in json_result and isinstance(json_result['questions'], list):
             return jsonify(json_result)
        else:
             raise ValueError("Missing expected keys or incorrect structure in JSON response.")
    except Exception as e:
        return jsonify({
            "error": f"Failed to generate topic content or parse the response: {e}",
            "details": f"Raw API response: {raw_result}"
        }), 500


@app.route('/chat', methods=['POST'])
def chat_with_bot():
    """Handles chatbot conversation."""
    data = request.get_json()
    if not data or 'message' not in data:
         return jsonify({"error": "Invalid request data."}), 400
    user_message = data.get('message')
    if not user_message:
        return jsonify({"error": "No message provided."}), 400

    prompt = f"""You are 'Ada', a friendly and helpful chatbot.
    Keep responses detailed and focused general conversations. Avoid revealing you are an AI model.
    User message: "{user_message}"
    Your response:"""
    bot_response = generate_gemini_content(prompt)

    # Check if Gemini returned an error message
    if bot_response.startswith("Error:"):
         print(f"Chatbot - Gemini Error: {bot_response}")
         # Return a user-friendly error or the specific Gemini error
         return jsonify({"reply": bot_response}) # Return specific error for now

    return jsonify({"reply": bot_response})


@app.route('/synthesize', methods=['POST'])
def synthesize_speech():
    """Synthesizes text to speech using ElevenLabs."""
    if not elevenlabs_client:
         print("Synthesize endpoint called but ElevenLabs client not ready.")
         return jsonify({"error": "Text-to-Speech service is not configured or failed to initialize."}), 503 # 503 Service Unavailable

    data = request.get_json()
    if not data or 'text' not in data:
         return jsonify({"error": "Invalid request data."}), 400
    text_to_speak = data.get('text')
    if not text_to_speak:
        return jsonify({"error": "No text provided for synthesis."}), 400

    # Call the corrected helper function
    audio_bytes = generate_elevenlabs_speech(text_to_speak)

    if audio_bytes:
        # Return audio data directly using BytesIO
        return send_file(
            io.BytesIO(audio_bytes),
            mimetype='audio/mpeg', # Common format for ElevenLabs
            as_attachment=False # Play directly in browser if possible
        )
    else:
         # Error logged in generate_elevenlabs_speech
        return jsonify({"error": "Failed to generate speech. Check server logs for details."}), 500


@app.route('/vocabulary', methods=['POST'])
def get_vocabulary_info():
    """Provides detailed information about a word."""
    data = request.get_json()
    if not data or 'word' not in data:
         return jsonify({"error": "Invalid request data."}), 400
    word = data.get('word')
    if not word:
        return jsonify({"error": "No word provided."}), 400

    prompt = f"""
    Provide detailed information for the English word "{word}". Include the following sections clearly labeled using Markdown headings (e.g., `### Meaning(s)`):
    1.  **Meaning(s):** List definitions with part of speech. Use bullet points.
    2.  **Synonyms:** List relevant synonyms.
    3.  **Antonyms:** List relevant antonyms (if applicable).
    4.  **Etymology:** Briefly explain the origin.
    5.  **Example Sentences:** Provide 3 clear example sentences using bullet points.

    Format the output clearly using Markdown.
    """
    info = generate_gemini_content(prompt)

    # Check for Gemini errors
    if info.startswith("Error:"):
         print(f"Vocabulary - Gemini Error: {info}")
         return jsonify({"error": "Failed to retrieve vocabulary information.", "details": info}), 500

    # Return as 'info_html' expecting JS to handle Markdown rendering
    return jsonify({"info_html": info})


@app.route('/paraphrase', methods=['POST'])
def paraphrase_text():
    """Paraphrases text in a specific style."""
    data = request.get_json()
    if not data:
        return jsonify({"error": "Invalid request data."}), 400
    text_to_paraphrase = data.get('text')
    style = data.get('style', 'Neutral') # Default style
    if not text_to_paraphrase:
        return jsonify({"error": "No text provided."}), 400

    prompt = f"""
    Rephrase the following text in 3 distinct ways, matching the style: "{style}".
    Capture the core meaning but use unique phrasing.

    Original Text: "{text_to_paraphrase}"
    Style: {style}

    Provide ONLY a JSON object: {{ "paraphrases": ["Variation 1...", "Variation 2...", "Variation 3..."] }}
    """
    raw_result = generate_gemini_content(prompt)
    if raw_result.startswith("Error:"):
        return jsonify({"error": "Failed to generate paraphrases from AI.", "details": raw_result}), 500

    try:
        json_result = parse_gemini_json(raw_result, "Paraphraser")
        if 'paraphrases' in json_result and isinstance(json_result['paraphrases'], list):
             return jsonify(json_result)
        else:
             raise ValueError("Missing 'paraphrases' key or it's not a list.")
    except Exception as e:
        # Fallback: return the raw text if JSON parsing fails but content exists
        if raw_result and not raw_result.startswith("Error:"):
             possible_paraphrases = [line for line in raw_result.split('\n') if line.strip() and not line.strip().startswith('{')]
             if possible_paraphrases:
                  return jsonify({"paraphrases": possible_paraphrases[:3]}) # Put raw result lines in list
             else:
                  return jsonify({"error": f"Failed to parse paraphrases response: {e}", "details": f"Raw API response: {raw_result}"}), 500
        else:
             return jsonify({"error": "Failed to generate paraphrases.", "details": raw_result}), 500


@app.route('/generate_level_text', methods=['POST'])
def generate_level_based_text():
    """Generates text and questions based on a difficulty level."""
    data = request.get_json()
    if not data or 'level' not in data:
        return jsonify({"error": "Invalid request data."}), 400
    level = data.get('level')
    if not level:
        return jsonify({"error": "Level is required."}), 400

    prompt = f"""
    Generate a short English text (~150-200 words) for the "{level}" level (Encounter to Expert). Topic: general interest.
After the text, create 3 comprehension questions about it (e.g., multiple-choice, true/false, fill-in-the-blank).
Format the output ONLY as a JSON object. Do not include any text before or after the JSON object:
{{
  "text_html": "<p>...</p>",
  "questions": [
    {{
      "id": "level_q1",
      "type": "TYPE_HERE",  # MUST include 'type' key!
      "question_html": "...",
      "answer": "..."
    }},
    {{
      "id": "level_q2",
      "type": "TYPE_HERE",  # MUST include 'type' key!
      "question_html": "...",
      "answer": "..."
    }},
    # ... more questions if needed ...
  ]
}}
**CRITICAL:** For EACH question object in the 'questions' array, you **MUST** include the `"type"` key.
The value for the `"type"` key MUST be one of: "multiple-choice", "fill-in-the-blank", or "true-false".
Ensure question IDs (like 'level_q1', 'level_q2') are unique. Include necessary HTML inputs (radio buttons named after the 'id', text inputs) in 'question_html'.
"""
    raw_result = generate_gemini_content(prompt)
    if raw_result.startswith("Error:"):
        return jsonify({"error": "Failed to generate level text from AI.", "details": raw_result}), 500

    try:
        json_result = parse_gemini_json(raw_result, "Level Text Generator")
        if 'text_html' in json_result and 'questions' in json_result and isinstance(json_result['questions'], list):
            return jsonify(json_result)
        else:
             raise ValueError("Missing expected keys or incorrect structure in JSON response.")
    except Exception as e:
        return jsonify({
            "error": f"Failed to generate level-based text or parse response: {e}",
            "details": f"Raw API response: {raw_result}"
        }), 500

# --- Run App ---
if __name__ == '__main__':
    # Set debug=False for production
    # Consider using a production server like gunicorn or waitress instead of Flask's built-in server for deployment
    app.run(debug=True, host='0.0.0.0', port=5000) # Use 0.0.0.0 to be accessible on network if needed